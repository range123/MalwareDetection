from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.svm import SVC

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_score, f1_score, accuracy_score, recall_score

import pandas as pd
import numpy as np
import pickle
import gensim

def store_model(filename,model):
    with open(filename,'wb') as f:
        pickle.dump(model,f)

def vectorize(s):
    tokens = gensim.utils.simple_preprocess(s)
    return model.infer_vector(tokens)

if __name__ == '__main__':

    ''' Dynamic Analysis '''
    df = pd.read_csv('./train_data_dynamic.csv')

    # Fill missing values
    df = df.fillna(-1).drop(columns=['file_name'],axis=1)

    # Create X and y
    X = df.drop(columns=['malware'],axis=1)
    y = df['malware']

    # Split into test and train
    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)

    # Scale the data
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train,y_train)
    X_test = scaler.transform(X_test)

    # Create Model
    clf = RandomForestClassifier(n_estimators=500,verbose=1)
    clf.fit(X_train,y_train)

    # Save the model and the scaler Object
    store_model('scaler.pkl',scaler)
    store_model('dynamic_classifier.pkl',clf)

    ''' Calculating Metrics for dynamic '''
    print('Dynamic Analysis Metrics')
    y_pred = clf.predict(X_test)
    print(f'Accuracy Score = {accuracy_score(y_test,y_pred)}')

    precision, recall, f1score = precision_score(y_test,y_pred), recall_score(y_test,y_pred), f1_score(y_test,y_pred) 
    print(f'Precision = {precision} Recall = {recall} F-score = {f1score}')

    ''' Static Analysis '''
    # Training doc2vec

    df = pd.read_csv('./train_data_static.csv')
    # df.set_index = range(len(df))
    def read_corpus(df, tokens_only=False):
        for i,line in enumerate(df.iloc[::1]):
            tokens = gensim.utils.simple_preprocess(line)
            # print(len(tokens),tokens[:50])
            if tokens_only:
                yield tokens
            else:
                # For training data, add tags
                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])
            if (i+1)%100 == 0:
                print(i+1)

    train_corpus = list(read_corpus(df['string']))
    model = gensim.models.doc2vec.Doc2Vec(vector_size=128, min_count=10, epochs=100)
    model.build_vocab(train_corpus)
    model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)
    model.save('./doc2vec/docmodel.model')



    X = []
    y = np.array(df['malware'])
    progress = 0
    for string in df['string']:
        X.append(vectorize(string))
        progress+=1
        if progress%100 == 0:
            print(progress)
    X = np.array(X)

    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)
    clf = RandomForestClassifier(n_estimators=1000)
    clf.fit(X_train,y_train)

    store_model('static_classifier.pkl',clf)

    ''' Calculating Metrics for static '''
    print('Static Analysis Metrics')
    y_pred = clf.predict(X_test)
    print(f'Accuracy Score = {accuracy_score(y_test,y_pred)}')

    precision, recall, f1score = precision_score(y_test,y_pred), recall_score(y_test,y_pred), f1_score(y_test,y_pred) 
    print(f'Precision = {precision} Recall = {recall} F-score = {f1score}')

